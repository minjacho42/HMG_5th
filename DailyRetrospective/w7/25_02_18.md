# 데일리 리뷰

날짜: 2025년 2월 18일
작성자: 최민제

# ✏️ Review

## EMR 설정

- EMR의 spark에서 python 외부 라이브러리를 사용하기 위해서는 bootstrap을 통해서 클러스터 실행 전에, 패키지를 install 해주어야 된다.
    
    > 이때, 그냥 `pip install pandas`와 같이 진행하게 되면, 마스터 노드에서만 설치가 진행되고 다른 core node에서는 설치가 되지 않는다.
    이 문제를 해결하기 위해서, stackoverflow를 찾아본 결과, `python3 -m pip install pandas`와 같은 방식으로 진행하면 성공한다는 사실을 알고 bootstrap을 변경한 결과, 제대로 core node에서도 설치가 되는 것을 확인할 수 있었다.
    > 

### pip install과 python3 -m pip install의 다른 점

- `python -m`은 인터프리터가 특정 모듈을 실행할 수 있도록 해주는 옵션이며, python3 -m으로 pip install을 진행하게 되면, 여러개의 파이썬 인터프리터가 있는 경우, 현재 쉘에서 사용 중인 인터프리터를 이용해 명시적으로 해당 인터프리터에 모듈을 설치할 수 있게 된다.

### EMR이 자꾸 꺼지는 이유

- EMR을 AWS SDK를 이용해서 클러스터를 실행하게 되면, 자동으로 step이 없으면 종료된다는 옵션이 추가된다. 그렇기에, 바로 step을 추가하여서, 클러스터가 deploy된 직후에 돌아갈 spark job을 submit 해야된다.

### EMR에서 OpenAI API를 사용하는 것에 대하여

- 어떠한 신차에 대한 언급이 있는 게시물의 컨텐츠에 대한 각 문장의 긍부정 척도를 확인하기 위해서 감성분석을 할 필요가 있었다.
- 하지만 spark는 cpu 기반의 분산 데이터 처리 프레임워크이기 때문에, 딥러닝 프레임워크를 직접 실행할 수 없다.
- 이를 위해서, 외부 api인 openAI를 불러와서 사용하게 되었으며, 좀 더 배치처리를 가능하게 하고, 효율적인 토큰 사용을 위해 한번에 여러 문장에 대한 request를 날리는 방향으로 API를 사용하게 되었다.

**→ 왜 EMR을 통한 transform이 끝난 이후에 진행하지 않았는가?**

1. Redshift도 쿼리에 대한 병렬처리를 진행하지만, Spark에서는 각 executor에서 병렬적으로 API 호출이 가능하기에 좀 더 효율적이다.
2. 또한 redshift에 적재 이후에 api call을 하게 되면, 불필요하게 redshift에서 데이터를 꺼내고 라벨링 이후에 다시 redshift에 넣게되는 두번의 불필요한 query I/O가 발생하게 되며, 이는 비용적으로 유리하지 못하기 때문이다.