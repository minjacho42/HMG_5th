# 데일리 리뷰

날짜: 2025년 1월 28일
작성자: 최민제

# ✏️ Review

## Spark

### Spark의 deploy options

- local
    - Single node이며, 로컬에 노드가 하나 있는 형태
- **Standalone Cluster**
    - Multinode로 구성되어있으며, Spark가 직접 리소스를 관리하는 형태.
    - 하나의 머신 내부에 여러개의 노드가 존재하게 된다.
    - 접근 방법은 `spark://host:port` 이다.
- Using a Cluster Manager
    - Multinode로 구성되어 있으며, spark가 아닌 yarn과 같은 리소스 매니저를 사용하는 형태.
    - 접근 방법은 `yarn://host:port`

### Driver and Executors

- spark에는 Driver와 Executor가 존재하게 된다.
- **Driver**는 SparkContext를 포함하고 있으며, application layer에 위치하지만, 마치 yarn(resource management layer)에서 application master가 하는 역할과 비슷한 일을 하게 된다.
- **Executor**는 실제 계산을 진행하게 된다.
- Driver가 생명주기동안 계속해서 executor의 생존 여부를 관리하기 때문에, driver는 계속해서 worker node들에 `network addressable` 해야 된다.

### Three Deploy Modes

- Local
- Cluster
    - Cluster 안에서 driver가 돌아가게 된다.
        
        즉, 훨씬 Fault Tolerance한 작업이 일어나게 된다.
        
    - 하지만, client와의 interactive한 명령이 불가능해진다.
    - driver가 cluster 내부에서 돌아가기 때문에, job submit 이후에 연결을 끊어도 상관이 없다.
- Client
    - Client 측에서 driver가 돌아가게 된다.
    - interactive 한 application이나 디버깅에 유용하다.

## Week4 Mission 1

- `/usr/local`과 `/opt`의 차이
    - `/usr/local`의 경우, 사용자가 직접 설치한 프로그램을 저장하는 곳이다.
    - `/opt`는 독립적인 서드파티 소프트웨어 패키지가 설치되는 곳이다.

# 🤔 Retrospective

## 🌟 Keep

- 쉬는 날임에도 불구하고!! 오늘 하루 열심히 공부하고 프로젝트를 진행하였다.
- W4에서 docker file을 작성하면서 겪을 시행착오를 기반으로, 이번 dockerfile은 비교적 수월하게 작성할 수 있었다. 내가 지금 겪는 시행착오는 이후에 큰 도움이 되니 두려워하지 말자.