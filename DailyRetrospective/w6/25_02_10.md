# 데일리 리뷰

날짜: 2025년 2월 10일
작성자: 최민제

# ✏️ Review

## Dataware House

- Dataware House로 사용되는 Amazon Redshift는 Columnar storage이다.

### Columnar storage

- Row를 기준으로 저장하던 Relational DB와 다르게, 하나의 column을 하나의 chunk로 저장하게 된다.
- Columnar storage는 Compression Efficiency, Column Pruning, Aggregation Performance과 같은 장점을 가지게 된다.

## LRU Cache를 이용하는 Spark의 특성

- Spark는 LRU Cache를 이용하며, 두가지 정보를 config해야된다.
    1. `spark.memory.fraction` 
        
        전체 Java heap 메모리에서 Reserved Memory (300MB)를 뺀 공간에서, user memory를 제외한 spark memory의 비율을 나타낸다.
        
    2. `spark.memory.storageFraction`
        
        spark memory 중에서 storage memory의 비율을 의미한다. 나머지 공간은 execution memory가 된다.
        

### Heap Memory의 구성 요소

- Storage Memory
    - Spark cache data를 저장한다. `ex) RDD cache`
- Execution Memory
    - Shuffle, Join Sort, Aggregation과 같은 연산을 위한 데이터를 저장한다.
- User Memory
    - RDD conversion operation을 위한 데이터를 저장한다.
- Reserved Memory
    - 스파크 관련 정보를 저장한다.

## Transformation Optimization을 위한 주요 기능들

### `sortWithinPartitions`

- sortWithinPartitions는 말그대로, 파티션 내부에서 소팅을 진행하기 때문에 셔플링을 최소화할 수 있다.

### `repartitionByRange`

- key의 범위를 기준으로 데이터를 나눠서 partitoning하는 방식이다. 이 방식을 통해서 이후에 셔플링을 최소화할 수 있다.

### Use `window` function

### Use `filtering` and `aggregation` instead of groupBy

## Cache, Persist, Checkpoint

### `cache()`

- 단순히 메모리 (캐시)에 저장을 하게 된다.
- LRU cache이기 때문에, 계속해서 caching후 쓰지 않는다면 날아갈 수 있다.

### `persist()`

- 여러가지 옵션으로 저장이 가능하며, 디스크에도 저장이 가능하다.
- 이때, 디스크는 해당 테스크가 돌아가고 있는 로컬에 저장한다.

### `checkpoint()`

- 디스크에 저장하며, 이후에 에러가 나도 쉽게 복구가 가능할 수 있도록, hdfs에 저장한다.
- 이전 두개의 방식과는 다르게 lineage가 끊긴채로 저장된다.

## Data Skewing

- Data skewing 즉, GroupBy를 진행하였을때, 한쪽 group이 엄청나게 큰 비율을 차지하게 되면
    1. Salting
    2. Splitting
    
    을 통해서 처리하게 된다.
    

## Broadcasting

- Join을 할 때, 한쪽의 DataFrame이 매우 작아서 cache memory 내부에 들어올 수 있다면, broadcast를 통해서 join이 가능하다.
- 이는 broadcast가 실패하게되면, out-of-memory가 뜨기 때문에 주의해서 사용할 필요가 있다.

## Filtering Unused Data

### Early filtering & Column pruning

- 빠르게 filtering을 진행함으로서, 이후의 연산에서 계속해서 이득을 볼 수 있도록 해야된다.
- 또한, Column pruning을 통해서 기본 연산 데이터 양을 줄일 수 있다.

# 🤔 Retrospective

## ⚠️ Problem

- 계속해서 함께 아키텍쳐를 설계하다보니, 쳐지고, 진도가 잘 안나가는 것을 확인할 수 있었다. 빠르게 데이터 파이프라인을 naive하게 설계한 이후에, 분업을 통해 세분화된 작업을 해나갈 필요가 있다고 느낀다.
- AWS에서 무엇이 안된다면 안되는 이유가 있지 않을까? 아니면 좀 차분하게 다른 방법을 생각해볼 필요가 있다. 어떻게든 해당 시각에 쏠려서 문제를 해결하려다보면, 잘못된 방향으로 가고 있을수도 있다.

## 🌟 Keep

- 할 일을 팀원들과 함께 세분화 하여 우선순위대로 한번 생각해보는 시간을 가졌다. 어떻게 분배를 해야될지 생각할 수 있는 주요한 시간이 되었다고 생각한다. 계속해서 할일을 세분화해서 잘 시간을 분배할 필요가 있다.

## 💡 Try