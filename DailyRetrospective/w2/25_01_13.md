# 데일리 리뷰

날짜: 2025년 1월 13일
작성자: 최민제

# ✏️ Review

## 📔 강의

### 5Vs of Big Data

- Velocity (데이터가 축적되는 속도)
- Volume (데이터의 크기)
- Variety (데이터의 종류)
- Veracity (데이터의 진실성 무결성)
- Value

### Fault Tolerance

데이터 관련 작업을 진행하게 되면, 단순히 몇십번이 아닌, 몇천번 이상의 작업들이 진행될 것이기 때문에, 같은 확률의 에러가 있더라도 좀 더 예외가 발생하는 경우가 많아질 것이다. 즉, 이를 위해서 에러처리에 좀 더 신경 쓸 필요가 있다.

High Availability를 위해서 여러가지 도구가 있고, 그 중 하나가 Fault Tolerance이다. 이외에도, Redundancy를 통해서 High Availability를 늘릴 수 있다.

## 🧑‍💻 과제

### Multiprocessing

- `spawn` vs `fork`
    - multiprocessing에서 main문이 아니면 process가 계속해서 반복문으로 불러와질 수 있다.
    - spawn의 경우에는 새로운 python 인터프리터를 시작하고 독립적인 프로세스를 생성하며, fork의 경우에는 기본적인 C언어의 새로운 프로세스를 생성하는 방식 처럼 부모 프로세스와 메모리를 공유하는 자식 프로세스가 생성된다.
    - 실험을 해보았을때, spawn으로 생성되게 되면
        
        ```sql
         5166 ttys001    0:00.05 /Library/Frameworks/Python.framework/Versions/3.13/Resources/Python.app/Contents/MacOS/Python w2m1.py
         5167 ttys001    0:00.03 /Library/Frameworks/Python.framework/Versions/3.13/Resources/Python.app/Contents/MacOS/Python -c from multiprocessing.resource_tracker import main;main(6)
         5168 ttys001    0:00.03 /Library/Frameworks/Python.framework/Versions/3.13/Resources/Python.app/Contents/MacOS/Python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=18) --multiprocessing-fork
         5169 ttys001    0:00.03 /Library/Frameworks/Python.framework/Versions/3.13/Resources/Python.app/Contents/MacOS/Python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=20) --multiprocessing-fork
        ```
        
        리소스 트래커와 spawn 메소드를 통해서 프로세스가 생성되게 된다. 즉, pool로 프로세스를 2개 만들어도, 총 3개의 프로세스가 생성되게 되는데, 나머지 하나의 프로세스는 작업 큐를 관리하고 결과를 수집하는 역할을 진행하게 된다.
        
- [**`multiprocessing.pool.Pool`](https://docs.python.org/ko/3.13/library/multiprocessing.html#multiprocessing.pool.Pool)**
    - Pool(processes=2) 와 같은 방식으로 pool을 만든다.
    - 2개의 워커 프로세스가 생성되며, `pool.map()` 을 통해서, 특정 함수와 매개변수를 넘겨주어서, 각 워커 프로세스가 어떠한 함수를 실행할 수 있도록 해준다.
    - `pool.starmap()` 을 통해서 함수가 *를 이용해 여러개의 매개변수를 한번에 받을 수 있는 메소드도 만들어준다.
- [`multiprocessing.Process`](https://docs.python.org/ko/3.13/library/multiprocessing.html#multiprocessing.Process)
    - `Process(target=, args=)` 를 이용해서 특정 함수를 실행하는 프로세스를 생성할 수 있다.
    - `start()` vs `run()`
        - start()는 새로운 프로세스에서 run()이 실행될 수 있게 해준다.
        - run()은 현재 프로세스에서 해당 target 함수가 실행된다.
    - `join()`
        - wait()와 같은 느낌으로 프로세스가 종료될 때 까지, 실행중인 부모 프로세스가 블록된다.
- [`multiprocessing.Queue`](https://docs.python.org/ko/3.13/library/multiprocessing.html#multiprocessing.Queue)
    - Queue는 maxsize=0으로 default값을 가지며, 그렇게 되면 최대 크기를 가지게 되는데, 실험해본 결과 대강 32768 정도의 길이를 가짐을 알 수 있었다. (운영체제의 pipe data 크기 제한으로 인한 값)
    - Queue는 pipe, lock, semapore를 이용해서 구현된다.
    - get_nowait(), put_nowait()를 이용하면, 큐가 비었거나 가득 찬 경우 각각 `queue.Empty`, `queue.Full` 에러가 발생한다.
    - 그냥 get(), put()을 사용하면, timeout이 설정된 경우 timeout 만큼 block하게 된다.
    - `empty()` 는 put()을 진행한 이후에 바로 불러오게 되면, 예상하는 상황과는 다른게 발생할 수 있는데, put이 진행되지 않은 상태에서 empty()를 불러와서 비어있는 상태로 표시되는 경우가 있다. 이를 해결하기 위해서 get()을 통해 queue에 값이 들어올 때 까지 block된 이후에 get을 받는 방법 등 여러가지 해결법이 존재한다.

## 기타

- Python serialize
- RPC

# 🤔 Retrospective

## ⚠️ Problem

- ETL적인 적용을 생각하면서 코드를 짜지 않고, 단순 문제의 요구사항에 맞춰서 코드를 작성하였다.
    
    → 추가적인 생각을 통해서 코드를 작성하면 추가적인 내용도 학습할 수 있는 기회가 생길 것. ex) mission4에서 각 프로세스가 transform task를 진행한다고 가정한 후에 코드를 작성하면, 어떠한 추가 코드를 작성할 수 있을까?
    

## 🌟 Keep

- python에서 제공해주는 api의 low level이 궁금하여, 팀원들과 함께 직접 소스코드를 까보면서 추가적인 연구를 진행하였다. 그 덕에 multiprocessing.Queue가 어떻게 구현되어있는지 파악할 수 있었다.
    
    → 궁금하다면 단순 ChatGPT를 이용하는 것이 아닌, 소스코드에 기반하여 추가적인 분석을 하는 방법도 좋은 공부법이 될 수  있을 것이다.
    

## 💡 Try